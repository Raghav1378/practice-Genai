{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7992f4-8f9a-4b6a-bf13-05293495e134",
      "metadata": {
        "id": "ff7992f4-8f9a-4b6a-bf13-05293495e134"
      },
      "outputs": [],
      "source": [
        "# Explore the langchain ecosystem/framework\n",
        "# Libraries - langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5867f626-114a-4c53-adb6-638cc630b914",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5867f626-114a-4c53-adb6-638cc630b914",
        "outputId": "3db5c311-d565-447a-f27d-ee3c8377587b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain==0.3.19\n",
            "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (0.3.60)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (9.1.2)\n",
            "Collecting numpy<2,>=1.26.4 (from langchain==0.3.19)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (1.20.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.19) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.19) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.19) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.19) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (1.3.1)\n",
            "Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, langchain\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.19 numpy-1.26.4\n",
            "Collecting langchain-openai==0.3.6\n",
            "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.6) (0.3.60)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.6) (1.81.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.6) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.6) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.6) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.6) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.35->langchain-openai==0.3.6) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.3.6) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.3.6) (2.4.0)\n",
            "Downloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.6\n"
          ]
        }
      ],
      "source": [
        "# Simple LangChain model\n",
        "!pip install langchain==0.3.19\n",
        "!pip install langchain-openai==0.3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4f3c65f5-0459-45a3-840c-490382130fbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3c65f5-0459-45a3-840c-490382130fbd",
        "outputId": "e8289446-a917-4c8f-c23b-72655365f155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "please enter your Open AI API KEY HERE ....:··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "OPENAI_KEY = getpass('please enter your Open AI API KEY HERE ....:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "83496ad9-a767-4674-b4c7-789658d83c7f",
      "metadata": {
        "id": "83496ad9-a767-4674-b4c7-789658d83c7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47402d11-d9b4-49ec-82d2-29894971b4fc",
      "metadata": {
        "id": "47402d11-d9b4-49ec-82d2-29894971b4fc"
      },
      "source": [
        "# **Models**\n",
        "**(LLM and ChatModel)**\n",
        "\n",
        "- A model can be a **LLM** or a **ChatModel**.\n",
        "- A Chat Model is a specialized version of an LLM that has been fine-tuned or adapted specifically for conversational interactions. It is designed to engage in back-and-forth dialogue with users.\n",
        "-Chat models are tailored for applications that require natural and engaging conversations, such as chatbots, virtual assistants, and customer support systems.\n",
        "- LLMs handle various language operations such as translation, summarization, question answering, and content creation. **[Click Here](https://python.langchain.com/docs/integrations/llms/)** to check the complete list of LLMs which can be used with LangChain.\n",
        "- Chat Models are customized for conversational usage. **[Click Here](https://python.langchain.com/docs/integrations/chat/)** to check the complete list of LLMs which can be used with LangChain.\n",
        "- The output of a ChatModel (and therefore, of this chain) is a message.\n",
        "\n",
        "| Module | LLM | Chat Model |\n",
        "| :---: | :---: | :---: |\n",
        "| langchain_openai | OpenAI(api_key=key, model=`gpt-3.5-turbo-instruct`) | ChatOpenAI(api_key=key, model=`gpt-3.5-turbo`) |\n",
        "| langchain_google_genai | GoogleGenerativeAI(api_key=key, model=`gemini-1.5-pro-latest`) | ChatGoogleGenerativeAI(api_key=key, model=`gemini-1.5-pro-latest`) |\n",
        "| langchain_cohere | Cohere(api_key=key, model=`command`) | ChatCohere(api_key=key, model=`command`) |\n",
        "| langchain_anthropic | Anthropic(api_key=key, model=`claude-2.1`) | ChatAnthropic(api_key=key, model=`claude-3-opus-20240229`) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b15cefde-68fc-4042-ba14-dcf8442d6edd",
      "metadata": {
        "id": "b15cefde-68fc-4042-ba14-dcf8442d6edd"
      },
      "outputs": [],
      "source": [
        "# Connect the LLM\n",
        "from langchain_openai import ChatOpenAI\n",
        "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f9d73ef2-4184-441a-af36-abe6358cfdcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9d73ef2-4184-441a-af36-abe6358cfdcd",
        "outputId": "7e8f46ee-effb-4803-c21a-8d9d1331f456"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-31949dbd6521>:12: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llmchain = LLMChain(llm=chatgpt, prompt=prompt_template)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'Explain Generative AI in a 3 line',\n",
              " 'text': 'Generative AI refers to algorithms that can create new content, such as text, images, or music, by learning patterns from existing data. It utilizes techniques like deep learning and neural networks to generate outputs that mimic human creativity. Applications include art generation, content creation, and even code writing.'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create LLM chain\n",
        "\n",
        "#An LLM Chain, within the context of LangChain, is a sequence of operations that uses a language model (LLM) to process input, potentially invoke\n",
        "#tools, and generate output, acting as a fundamental building block for more complex applications.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt_txt = \"{query}\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt_txt)\n",
        "#ChatPromptTemplate: This represents a class (likely a part of a library) that is used to create a prompt template specifically for conversational\n",
        "#models. It is designed to define and manage how inputs to a chat model should be structured.\n",
        "llmchain = LLMChain(llm=chatgpt, prompt=prompt_template)\n",
        "\n",
        "# Run the LLM Chain\n",
        "response = llmchain.invoke({'query':'Explain Generative AI in a 3 line'})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf4689c0-2d2c-4299-840e-e4f1b3508c05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf4689c0-2d2c-4299-840e-e4f1b3508c05",
        "outputId": "917725d9-e41f-4237-91da-89a679246464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generative AI refers to algorithms that can create new content, such as text, images, music, or videos, by learning patterns from existing data. It utilizes techniques like deep learning and neural networks to generate outputs that mimic human creativity. Applications include art generation, content creation, and even code writing, transforming various industries.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt_txt = \"{query}\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt_txt)\n",
        "llmchain = LLMChain(llm=chatgpt, prompt=prompt_template)\n",
        "\n",
        "# Run the LLM Chain\n",
        "response = llmchain.invoke({'query':'Explain Generative AI in a 3 line'})\n",
        "print(response['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e4702c2-dbda-4c8c-80ab-e3e09c6da970",
      "metadata": {
        "id": "5e4702c2-dbda-4c8c-80ab-e3e09c6da970"
      },
      "source": [
        "# Create LCEL llm chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ac98173a-1267-4b18-bd9a-4d42c744471a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac98173a-1267-4b18-bd9a-4d42c744471a",
        "outputId": "71ed56d2-a326-4f5b-d103-47028cac3ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generative AI refers to algorithms that can create new content, such as text, images, or music, by learning patterns from existing data. It utilizes techniques like deep learning and neural networks to generate outputs that mimic human creativity. Applications include art generation, content creation, and even code writing, transforming various industries.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt_txt = \"{query}\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt_txt)\n",
        "llmchain = (prompt_template | chatgpt)\n",
        "response = llmchain.invoke({'query':'Explain Generative AI in a 3 line'})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HfWEy3plmwCz",
      "metadata": {
        "id": "HfWEy3plmwCz"
      },
      "source": [
        "**The prompt_template | model is essentially the same as calling LLMChain(prompt=prompt_template, llm=model), but it’s a more modular, flexible syntax that can be useful in larger pipelines where multiple steps might be needed.**\n",
        "\n",
        "**A large pipeline might look like this:**\n",
        "\n",
        "1. Preprocessing: Clean and tokenize input.\n",
        "\n",
        "2. Dynamic Prompt Construction: Build a context-aware prompt.\n",
        "\n",
        "3. Model Interaction: Query the model based on the prompt.\n",
        "\n",
        "4. Post-Processing: Format or summarize the output.\n",
        "\n",
        "5. Conditional Logic: Apply different logic or pathways based on the output.\n",
        "\n",
        "6. Safety/Quality Checks: Filter or rank the output.\n",
        "\n",
        "7. State Management: Update conversation history or store results for later.\n",
        "\n",
        "8. Logging: Log the interactions and results for monitoring.\n",
        "\n",
        "\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    dynamic_prompt = construct_dynamic_prompt(processed_input)\n",
        "    raw_output = dynamic_prompt | model\n",
        "    final_output = post_process(raw_output)\n",
        "    safe_output = filter_inappropriate_content(final_output)\n",
        "    log_result(user_input, safe_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c6856b6f-68f7-4fce-9ea0-8fb4d561ab85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6856b6f-68f7-4fce-9ea0-8fb4d561ab85",
        "outputId": "e3404304-376f-465f-e497-8a498e840284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Generative AI refers to algorithms that can create new content, such as text, images, music, or videos, by learning patterns from existing data. It utilizes techniques like deep learning and neural networks to generate outputs that mimic human creativity. Applications include art generation, content creation, and even code writing, transforming various industries.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 16, 'total_tokens': 80, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--80bf26ce-52c6-4e9d-922d-5a59b86536ee-0', usage_metadata={'input_tokens': 16, 'output_tokens': 64, 'total_tokens': 80, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt_txt = \"{query}\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt_txt)\n",
        "llmchain = (prompt_template | chatgpt)\n",
        "response = llmchain.invoke({'query':'Explain Generative AI in a 3 line'})\n",
        "response\n",
        "\n",
        "'''\n",
        "prompt_txt = \"\"\"\n",
        "You are a helpful assistant.\n",
        "Please follow the instructions carefully.\n",
        "\n",
        "{query}\n",
        "\"\"\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "30b0f987-514e-4e0f-b77b-88084c734598",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "30b0f987-514e-4e0f-b77b-88084c734598",
        "outputId": "0c58f8a8-3f9d-426e-c259-241e1e837771"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Deep learning is a subset of machine learning, which itself is a branch of artificial intelligence (AI). It involves the use of neural networks with many layers (hence \"deep\") to model and understand complex patterns in large amounts of data. Here are some key aspects of deep learning:\\n\\n1. **Neural Networks**: Deep learning primarily uses artificial neural networks, which are inspired by the structure and function of the human brain. These networks consist of layers of interconnected nodes (neurons) that process data.\\n\\n2. **Layers**: A deep neural network typically has an input layer, multiple hidden layers, and an output layer. Each layer transforms the input data into a more abstract representation, allowing the model to learn hierarchical features.\\n\\n3. **Training**: Deep learning models are trained using large datasets. During training, the model adjusts its weights and biases through a process called backpropagation, which minimizes the difference between the predicted output and the actual output (loss).\\n\\n4. **Applications**: Deep learning has been successfully applied in various fields, including:\\n   - **Computer Vision**: Image recognition, object detection, and image generation.\\n   - **Natural Language Processing (NLP)**: Language translation, sentiment analysis, and text generation.\\n   - **Speech Recognition**: Converting spoken language into text.\\n   - **Reinforcement Learning**: Training agents to make decisions in complex environments.\\n\\n5. **Advantages**: Deep learning can automatically extract features from raw data, reducing the need for manual feature engineering. It is particularly effective for tasks involving unstructured data, such as images, audio, and text.\\n\\n6. **Challenges**: Deep learning models require large amounts of labeled data and significant computational resources for training. They can also be prone to overfitting and may lack interpretability, making it difficult to understand how they arrive at specific decisions.\\n\\nOverall, deep learning has revolutionized many areas of technology and continues to be a rapidly evolving field with ongoing research and development.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = llmchain.invoke({'query':'what is Deep Learning'})\n",
        "response.content"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
